{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1d6ceafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "from typing import Dict, Optional\n",
    "\n",
    "from matplotlib.axes import Axes\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.rcParams[\"figure.dpi\"] = 300\n",
    "plt.rcParams[\"savefig.dpi\"] = 300\n",
    "sns.set_theme()\n",
    "sns.set_context(\"talk\")  # paper, notebook, talk, and poster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "e8905760",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hist(ax: Axes, data: torch.Tensor, label: str) -> None:\n",
    "    \"\"\"\n",
    "    Plot a histogram of the data.\n",
    "\n",
    "    Args:\n",
    "        ax (matplotlib.axes.Axes): The axes to plot on.\n",
    "        data (torch.Tensor): The data to plot.\n",
    "        label (str): The label of the data.\n",
    "    \"\"\"\n",
    "\n",
    "    sns.histplot(data, ax=ax, kde=True, stat=\"density\")\n",
    "    ax.set_xlabel(label)\n",
    "    ax.set_ylabel(\"Density\")\n",
    "    # write the mean and std to the top center of image\n",
    "    mean = data.mean()\n",
    "    std = data.std()\n",
    "    ax.text(\n",
    "        0.5,\n",
    "        0.95,\n",
    "        f\"Mean: {mean:.2f}, Std: {std:.2f}\",\n",
    "        horizontalalignment=\"center\",\n",
    "        transform=ax.transAxes,\n",
    "    )\n",
    "\n",
    "\n",
    "def compute_gap_statistics(\n",
    "    features1: torch.Tensor,\n",
    "    features2: torch.Tensor,\n",
    "    labels1: Optional[torch.Tensor],\n",
    "    labels2: Optional[torch.Tensor],\n",
    "    n_class: Optional[int],\n",
    "    title: str,\n",
    "    name: Optional[str]\n",
    ") -> Dict:\n",
    "    \"\"\"\n",
    "    Compute the statistics of the modality gap between features from two different modalities.\n",
    "\n",
    "    Args:\n",
    "        features1 (torch.Tensor): Features from the first modality.\n",
    "        features2 (torch.Tensor): Features from the second modality.\n",
    "        labels1 (torch.Tensor): Labels for the first modality.\n",
    "        labels2 (torch.Tensor): Labels for the second modality.\n",
    "        n_class (int): The number of classes.\n",
    "        title (str): The title of the plot.\n",
    "\n",
    "    Returns:\n",
    "        Dict: A dictionary containing the statistics of the modality gap.\n",
    "    \"\"\"\n",
    "\n",
    "    assert (\n",
    "        len(features1.shape) == 2 and len(features2.shape) == 2\n",
    "    ), \"Features should be 2D.\"\n",
    "\n",
    "    features1, features2 = F.normalize(features1), F.normalize(features2)\n",
    "\n",
    "    if labels1 is not None and labels2 is not None and n_class is not None:\n",
    "        assert (\n",
    "            features1.shape[0] == labels1.shape[0]\n",
    "            and features2.shape[0] == labels2.shape[0]\n",
    "        ), \"Features and labels should have the same number of samples.\"\n",
    "        gaps = []\n",
    "        for i in range(n_class):\n",
    "            if len(labels1.shape) == 1:\n",
    "                class_features1 = features1[labels1 == i]\n",
    "                class_features2 = features2[labels2 == i]\n",
    "            elif len(labels1.shape) == 2:\n",
    "                class_features1 = features1[labels1[:, i] == 1]\n",
    "                class_features2 = features2[labels2[:, i] == 1]\n",
    "            else:\n",
    "                raise ValueError(\"Labels should be 1D or 2D.\")\n",
    "            gaps.append(class_features1.mean(dim=0) - class_features2.mean(dim=0))\n",
    "        gaps = torch.stack(gaps, dim=0)\n",
    "    else:\n",
    "        assert (\n",
    "            features1.shape == features2.shape\n",
    "        ), \"Features are from paired inputs so they should have the same shape.\"\n",
    "        gaps = features1 - features2\n",
    "\n",
    "    figsize = (24, 6)\n",
    "\n",
    "    fig, ax = plt.subplots(1, 4, figsize=figsize)\n",
    "\n",
    "    magnitudes = gaps.norm(dim=-1)\n",
    "    hist(ax[0], magnitudes, \"Magnitude\")\n",
    "\n",
    "    directions = F.cosine_similarity(gaps, gaps.mean(dim=0))\n",
    "    hist(ax[1], directions, \"Direction\")\n",
    "\n",
    "    orthogonalities = F.cosine_similarity(\n",
    "        features1 - features1.mean(dim=0), gaps.mean(dim=0)\n",
    "    )\n",
    "    hist(ax[2], orthogonalities, \"Orthogonality\")\n",
    "\n",
    "    gap_direction = F.normalize(gaps.mean(dim=0), dim=0)\n",
    "    features1_projections = features1 @ gap_direction\n",
    "    features1_residues = (\n",
    "        features1 - features1_projections[:, None] * gap_direction[None, :]\n",
    "    )\n",
    "    centerings = features1_residues.mean(dim=0)\n",
    "    hist(ax[3], centerings, \"Centering\")\n",
    "\n",
    "    fig.suptitle(title)\n",
    "    # plt.show()\n",
    "    plt.savefig(f\"{name}.pdf\")\n",
    "\n",
    "    return {\n",
    "        \"magnitude\": magnitudes,\n",
    "        \"direction\": directions,\n",
    "        \"orthogonality\": orthogonalities,\n",
    "        \"centering\": centerings,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "d84141d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 768])\n",
      "torch.Size([100, 768])\n",
      "torch.Size([5000, 768])\n",
      "torch.Size([5000, 768])\n"
     ]
    }
   ],
   "source": [
    "AVG_OUTPUT_EMBED_FOLDER = f\"./data/dalle2/coco_prior_output_ViT-L_14_train_mini_avg_100x50\"\n",
    "\n",
    "features = torch.load(f\"{AVG_OUTPUT_EMBED_FOLDER}/features.pt\")\n",
    "all_features = torch.load(f\"{AVG_OUTPUT_EMBED_FOLDER}/features_all.pt\")\n",
    "\n",
    "print(features[\"image_features\"].shape)\n",
    "print(features[\"text_features\"].shape)\n",
    "\n",
    "# Diffusion prior input and average output\n",
    "_ = compute_gap_statistics(\n",
    "    features[\"image_features\"].float(), features[\"text_features\"].float(), None, None, None, \"CLIP COCO\", name=\"diffusion_prior_gap\"\n",
    ")\n",
    "\n",
    "# Diffusion prior output and average output\n",
    "hidden_dim = all_features[\"image_features\"].shape[-1]\n",
    "num_repeats = all_features[\"image_features\"].shape[1]\n",
    "\n",
    "features_output_all = all_features[\"image_features\"].float().reshape(-1, hidden_dim)\n",
    "features_avg_repeated = features[\"image_features\"].repeat((1, num_repeats, 1)).float().reshape(-1, hidden_dim)\n",
    "\n",
    "print(features_avg_repeated.shape)\n",
    "print(features_output_all.shape)\n",
    "\n",
    "_ = compute_gap_statistics(\n",
    "    features_output_all, features_avg_repeated, None, None, None, \"CLIP COCO\", name=\"diffusion_prior_noise\"\n",
    ")\n",
    "\n",
    "\n",
    "# _ = compute_gap_statistics(\n",
    "#     features[\"image_features\"],\n",
    "#     features[\"text_features\"],\n",
    "#     features[\"labels\"],\n",
    "#     features[\"labels\"],\n",
    "#     100,\n",
    "#     \"CLIP COCO Class\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e75a97b-0f96-4405-b496-6f0a8de13c88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
